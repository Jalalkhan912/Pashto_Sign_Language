{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec0438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcc02e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the CSV\n",
    "csv_path = \"hand_keypoints_dataset.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2. Extract keypoints and labels\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# 3. Normalize keypoints relative to bounding box\n",
    "def normalize_keypoints(keypoints):\n",
    "    keypoints = keypoints.reshape(21, 3)\n",
    "    x_coords = keypoints[:, 0]\n",
    "    y_coords = keypoints[:, 1]\n",
    "\n",
    "    x_min, x_max = x_coords.min(), x_coords.max()\n",
    "    y_min, y_max = y_coords.min(), y_coords.max()\n",
    "\n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "\n",
    "    # Avoid division by zero\n",
    "    width = width if width != 0 else 1e-6\n",
    "    height = height if height != 0 else 1e-6\n",
    "\n",
    "    keypoints[:, 0] = (x_coords - x_min) / width\n",
    "    keypoints[:, 1] = (y_coords - y_min) / height\n",
    "    return keypoints.flatten()\n",
    "\n",
    "X_norm = np.array([normalize_keypoints(sample) for sample in X])\n",
    "\n",
    "# 4. Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 5. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_norm)\n",
    "\n",
    "# Save the scaler and label encoder\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "# 6. Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6face10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create PyTorch Dataset\n",
    "class HandKeypointDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = HandKeypointDataset(X_train, y_train)\n",
    "test_dataset = HandKeypointDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# 8. Define a simple dense neural network\n",
    "class PashtoSignClassifier(nn.Module):\n",
    "    def __init__(self, input_size=63, num_classes=len(np.unique(y_encoded))):\n",
    "        super(PashtoSignClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = PashtoSignClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59e75cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Loss: 33.6360 - Accuracy: 0.9445\n",
      "Epoch 2/100 - Loss: 33.2295 - Accuracy: 0.9404\n",
      "Epoch 3/100 - Loss: 32.3820 - Accuracy: 0.9488\n",
      "Epoch 4/100 - Loss: 30.9703 - Accuracy: 0.9460\n",
      "Epoch 5/100 - Loss: 29.1339 - Accuracy: 0.9525\n",
      "Epoch 6/100 - Loss: 30.3841 - Accuracy: 0.9501\n",
      "Epoch 7/100 - Loss: 27.8118 - Accuracy: 0.9546\n",
      "Epoch 8/100 - Loss: 28.8814 - Accuracy: 0.9497\n",
      "Epoch 9/100 - Loss: 29.7155 - Accuracy: 0.9502\n",
      "Epoch 10/100 - Loss: 26.8162 - Accuracy: 0.9537\n",
      "Epoch 11/100 - Loss: 26.1518 - Accuracy: 0.9546\n",
      "Epoch 12/100 - Loss: 26.7944 - Accuracy: 0.9535\n",
      "Epoch 13/100 - Loss: 26.5855 - Accuracy: 0.9571\n",
      "Epoch 14/100 - Loss: 26.0954 - Accuracy: 0.9568\n",
      "Epoch 15/100 - Loss: 23.9495 - Accuracy: 0.9622\n",
      "Epoch 16/100 - Loss: 25.7928 - Accuracy: 0.9553\n",
      "Epoch 17/100 - Loss: 23.3290 - Accuracy: 0.9597\n",
      "Epoch 18/100 - Loss: 25.2665 - Accuracy: 0.9537\n",
      "Epoch 19/100 - Loss: 26.8264 - Accuracy: 0.9542\n",
      "Epoch 20/100 - Loss: 24.9719 - Accuracy: 0.9594\n",
      "Epoch 21/100 - Loss: 25.2568 - Accuracy: 0.9583\n",
      "Epoch 22/100 - Loss: 23.1650 - Accuracy: 0.9628\n",
      "Epoch 23/100 - Loss: 23.9088 - Accuracy: 0.9556\n",
      "Epoch 24/100 - Loss: 22.2742 - Accuracy: 0.9628\n",
      "Epoch 25/100 - Loss: 23.4311 - Accuracy: 0.9597\n",
      "Epoch 26/100 - Loss: 23.3594 - Accuracy: 0.9617\n",
      "Epoch 27/100 - Loss: 20.9992 - Accuracy: 0.9653\n",
      "Epoch 28/100 - Loss: 22.2922 - Accuracy: 0.9623\n",
      "Epoch 29/100 - Loss: 20.7214 - Accuracy: 0.9650\n",
      "Epoch 30/100 - Loss: 20.4187 - Accuracy: 0.9653\n",
      "Epoch 31/100 - Loss: 21.3575 - Accuracy: 0.9630\n",
      "Epoch 32/100 - Loss: 21.2892 - Accuracy: 0.9646\n",
      "Epoch 33/100 - Loss: 20.1004 - Accuracy: 0.9643\n",
      "Epoch 34/100 - Loss: 20.7786 - Accuracy: 0.9640\n",
      "Epoch 35/100 - Loss: 19.0675 - Accuracy: 0.9669\n",
      "Epoch 36/100 - Loss: 20.3112 - Accuracy: 0.9674\n",
      "Epoch 37/100 - Loss: 20.7133 - Accuracy: 0.9628\n",
      "Epoch 38/100 - Loss: 18.9113 - Accuracy: 0.9668\n",
      "Epoch 39/100 - Loss: 20.0192 - Accuracy: 0.9641\n",
      "Epoch 40/100 - Loss: 21.0548 - Accuracy: 0.9620\n",
      "Epoch 41/100 - Loss: 17.8021 - Accuracy: 0.9651\n",
      "Epoch 42/100 - Loss: 19.3407 - Accuracy: 0.9676\n",
      "Epoch 43/100 - Loss: 21.2661 - Accuracy: 0.9622\n",
      "Epoch 44/100 - Loss: 19.0341 - Accuracy: 0.9682\n",
      "Epoch 45/100 - Loss: 17.2380 - Accuracy: 0.9692\n",
      "Epoch 46/100 - Loss: 18.7635 - Accuracy: 0.9679\n",
      "Epoch 47/100 - Loss: 17.0034 - Accuracy: 0.9692\n",
      "Epoch 48/100 - Loss: 18.0057 - Accuracy: 0.9697\n",
      "Epoch 49/100 - Loss: 20.2238 - Accuracy: 0.9674\n",
      "Epoch 50/100 - Loss: 17.3589 - Accuracy: 0.9720\n",
      "Epoch 51/100 - Loss: 16.1351 - Accuracy: 0.9712\n",
      "Epoch 52/100 - Loss: 16.7567 - Accuracy: 0.9707\n",
      "Epoch 53/100 - Loss: 15.9878 - Accuracy: 0.9718\n",
      "Epoch 54/100 - Loss: 18.3628 - Accuracy: 0.9697\n",
      "Epoch 55/100 - Loss: 18.4385 - Accuracy: 0.9699\n",
      "Epoch 56/100 - Loss: 16.7516 - Accuracy: 0.9689\n",
      "Epoch 57/100 - Loss: 17.2886 - Accuracy: 0.9715\n",
      "Epoch 58/100 - Loss: 18.1688 - Accuracy: 0.9687\n",
      "Epoch 59/100 - Loss: 14.8030 - Accuracy: 0.9754\n",
      "Epoch 60/100 - Loss: 16.3616 - Accuracy: 0.9702\n",
      "Epoch 61/100 - Loss: 14.1026 - Accuracy: 0.9758\n",
      "Epoch 62/100 - Loss: 15.8514 - Accuracy: 0.9735\n",
      "Epoch 63/100 - Loss: 15.6049 - Accuracy: 0.9712\n",
      "Epoch 64/100 - Loss: 15.9298 - Accuracy: 0.9718\n",
      "Epoch 65/100 - Loss: 14.9657 - Accuracy: 0.9735\n",
      "Epoch 66/100 - Loss: 14.7606 - Accuracy: 0.9751\n",
      "Epoch 67/100 - Loss: 14.9035 - Accuracy: 0.9710\n",
      "Epoch 68/100 - Loss: 15.5063 - Accuracy: 0.9709\n",
      "Epoch 69/100 - Loss: 14.7597 - Accuracy: 0.9743\n",
      "Epoch 70/100 - Loss: 15.9434 - Accuracy: 0.9740\n",
      "Epoch 71/100 - Loss: 14.8074 - Accuracy: 0.9746\n",
      "Epoch 72/100 - Loss: 14.0622 - Accuracy: 0.9754\n",
      "Epoch 73/100 - Loss: 15.5142 - Accuracy: 0.9741\n",
      "Epoch 74/100 - Loss: 12.1422 - Accuracy: 0.9797\n",
      "Epoch 75/100 - Loss: 14.9856 - Accuracy: 0.9738\n",
      "Epoch 76/100 - Loss: 15.6698 - Accuracy: 0.9718\n",
      "Epoch 77/100 - Loss: 12.9622 - Accuracy: 0.9769\n",
      "Epoch 78/100 - Loss: 13.9169 - Accuracy: 0.9748\n",
      "Epoch 79/100 - Loss: 15.2140 - Accuracy: 0.9733\n",
      "Epoch 80/100 - Loss: 14.0161 - Accuracy: 0.9782\n",
      "Epoch 81/100 - Loss: 13.8569 - Accuracy: 0.9750\n",
      "Epoch 82/100 - Loss: 14.5662 - Accuracy: 0.9753\n",
      "Epoch 83/100 - Loss: 13.4163 - Accuracy: 0.9763\n",
      "Epoch 84/100 - Loss: 15.1907 - Accuracy: 0.9717\n",
      "Epoch 85/100 - Loss: 14.4208 - Accuracy: 0.9763\n",
      "Epoch 86/100 - Loss: 14.5270 - Accuracy: 0.9753\n",
      "Epoch 87/100 - Loss: 12.4475 - Accuracy: 0.9771\n",
      "Epoch 88/100 - Loss: 13.2490 - Accuracy: 0.9766\n",
      "Epoch 89/100 - Loss: 14.0782 - Accuracy: 0.9768\n",
      "Epoch 90/100 - Loss: 13.5649 - Accuracy: 0.9784\n",
      "Epoch 91/100 - Loss: 13.6933 - Accuracy: 0.9746\n",
      "Epoch 92/100 - Loss: 12.3764 - Accuracy: 0.9768\n",
      "Epoch 93/100 - Loss: 13.2866 - Accuracy: 0.9771\n",
      "Epoch 94/100 - Loss: 13.7348 - Accuracy: 0.9750\n",
      "Epoch 95/100 - Loss: 13.2607 - Accuracy: 0.9768\n",
      "Epoch 96/100 - Loss: 12.8453 - Accuracy: 0.9759\n",
      "Epoch 97/100 - Loss: 12.9505 - Accuracy: 0.9779\n",
      "Epoch 98/100 - Loss: 11.7049 - Accuracy: 0.9797\n",
      "Epoch 99/100 - Loss: 12.5150 - Accuracy: 0.9753\n",
      "Epoch 100/100 - Loss: 14.3217 - Accuracy: 0.9743\n",
      "✅ Model saved as gesture_classifier.pth\n"
     ]
    }
   ],
   "source": [
    "# 9. Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "\n",
    "    acc = correct / len(train_dataset)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f} - Accuracy: {acc:.4f}\")\n",
    "\n",
    "# 10. Save the trained model\n",
    "torch.save(model.state_dict(), \"gesture_classifier.pth\")\n",
    "print(\"✅ Model saved as gesture_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7597b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9771\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model weights\n",
    "model.load_state_dict(torch.load(\"gesture_classifier.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = model(batch_X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == batch_y).sum().item()\n",
    "        total += batch_y.size(0)\n",
    "\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d049ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
